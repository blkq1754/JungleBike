# ğŸš´â€â™‚ï¸ Classification de CatÃ©gories de Produits VÃ©lo

## Introduction

Ce projet implÃ©mente un pipeline complet pour la classification de produits techniques de vÃ©lo Ã  partir de leurs informations textuelles. L'objectif Ã©tait non seulement de construire un modÃ¨le performant, mais surtout d'Ã©valuer et de comparer deux approches distinctes : une solution de **Machine Learning classique** (rapide et efficace) et une solution de **Deep Learning de pointe** (basÃ©e sur un modÃ¨le Transformer).

Le projet met l'accent sur la robustesse, la reproductibilitÃ© et les bonnes pratiques d'ingÃ©nierie logicielle, incluant la gestion de l'environnement, les tests unitaires, l'optimisation des modÃ¨les et la crÃ©ation d'une interface de dÃ©monstration interactive.

* **DÃ©mo en Ligne :** [Lien vers l'application Gradio sur Hugging Face Spaces](https://huggingface.co/spaces/belkacemsaad/demo_JungleBike)
* **Auteur :** Saad Belkacem

---

## Tableau Comparatif des Performances 

| MÃ©trique | ModÃ¨le Classique (TF-IDF + LogReg) | ModÃ¨le Transformer (CamemBERT) | Commentaire |
| :--- | :--- | :--- | :--- |
| **PrÃ©cision (Accuracy)** | 98.0% | **99.0%** | Le Transformer est lÃ©gÃ¨rement supÃ©rieur. |
| **F1-Score (PondÃ©rÃ©)** | 98.0% | **99.0%** | Confirme la meilleure performance globale du Transformer. |
| **Robustesse (classes rares)** | Faible (plusieurs Ã©checs) | **Ã‰levÃ©e** | Le Transformer gÃ¨re beaucoup mieux les cas rares. |
| **Temps d'EntraÃ®nement** | **~ 1 minute** | ~ 2-3 heures (sur GPU) | Le modÃ¨le classique est des ordres de grandeur plus rapide Ã  entraÃ®ner. |
| **Vitesse d'InfÃ©rence (CPU)** | **~ 11 IPS** | Lente | Le modÃ¨le classique est le choix Ã©vident pour un dÃ©ploiement CPU. |
| **ComplexitÃ© & Maintenance**| **Faible** | Ã‰levÃ©e | Le pipeline scikit-learn est beaucoup plus simple Ã  maintenir. |

---

## ğŸ—‚ï¸ Structure du Projet

Le projet est organisÃ© de maniÃ¨re modulaire pour une meilleure clartÃ© et maintenabilitÃ©.

```
.
â”œâ”€â”€ classic_ml/               # Pipeline du modÃ¨le classique (TF-IDF + LogReg)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ data/                       # DonnÃ©es (non versionnÃ©es par Git)
â”œâ”€â”€ evaluation/                 # Scripts et rÃ©sultats d'Ã©valuation
â”‚   â”œâ”€â”€ classic_model_results/
â”‚   â”œâ”€â”€ transformer_model_results/
â”‚   â”œâ”€â”€ evaluate_classic.py
â”‚   â””â”€â”€ evaluate_transformer.py
â”œâ”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ classic_model.joblib
â”‚   â”œâ”€â”€ product_classifier.onnx
â”‚   â””â”€â”€ dataset_target_map.json
â”œâ”€â”€ scripts/                    # Scripts d'action pour le pipeline Transformer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ export_and_benchmark.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ src/                        # Code source partagÃ© (modÃ¨le Transformer, prÃ©-traitement)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/                      # Tests unitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_*.py
â”œâ”€â”€ app.py                      # Application de dÃ©mo Gradio
â”œâ”€â”€ pyproject.toml              # Fichier de configuration Poetry
â””â”€â”€ README.md                   # Ce document
```

---

## âš™ï¸ Guide d'Installation et d'Utilisation

Ce guide dÃ©taille comment installer l'environnement et exÃ©cuter chaque script du projet.

### 1. Installation

Le projet utilise **Poetry** pour la gestion de l'environnement et des dÃ©pendances.

```bash
# 1. Cloner le dÃ©pÃ´t
git clone [https://github.com/blkq1754/Jungle-Bike.git](https://github.com/blkq1754/Jungle-Bike.git)
cd Jungle-Bike

# 2. Installer les dÃ©pendances
poetry install
```

### 2. Workflow Complet

Le workflow est conÃ§u pour Ãªtre modulaire. Voici comment utiliser chaque script :

#### Ã‰tape A : Tester l'Environnement (Optionnel)

Ce script valide que la prÃ©paration des donnÃ©es fonctionne comme prÃ©vu.

```bash
poetry run pytest
```

#### Ã‰tape B : PrÃ©-traitement des DonnÃ©es pour le ModÃ¨le Transformer

Ce script prÃ©pare et tokenize les donnÃ©es, nÃ©cessaire avant d'entraÃ®ner le modÃ¨le Transformer.

```bash
# ExÃ©cutÃ© depuis la racine du projet
poetry run python -m scripts.preprocess
```

#### Ã‰tape C : EntraÃ®ner les ModÃ¨les (Optionnel)

Les modÃ¨les Ã©tant dÃ©jÃ  fournis, cette Ã©tape est optionnelle.

* **EntraÃ®ner le ModÃ¨le Classique (TF-IDF + LogReg) :**
    ```bash
    poetry run python -m classic_ml.train
    ```
* **EntraÃ®ner le ModÃ¨le Transformer (CamemBERT) :**
    ```bash
    poetry run python -m scripts.train
    ```

#### Ã‰tape D : Ã‰valuer les ModÃ¨les

Ces scripts gÃ©nÃ¨rent les rapports de performance et les matrices de confusion dans le dossier `evaluation/`.

* **Ã‰valuer le ModÃ¨le Classique :**
    ```bash
    poetry run python -m evaluation.evaluate_classic
    ```
* **Ã‰valuer le ModÃ¨le Transformer :**
    ```bash
    poetry run python -m evaluation.evaluate_transformer
    ```

#### Ã‰tape E : Lancer la DÃ©monstration Interactive

Ce script lance une interface web locale pour tester les modÃ¨les.
```bash
poetry run python app.py
```
Ouvrez l'URL fournie (ex: `http://127.0.0.1:7860`) dans votre navigateur.

---

## ë°Ÿ DÃ©marche Technique et DÃ©cisions ClÃ©s

### 1. PrÃ©paration du Dataset

* **ProblÃ¨me :** IncohÃ©rence des labels et distribution trÃ¨s dÃ©sÃ©quilibrÃ©e des catÃ©gories ("longue traÃ®ne").
* **DÃ©cision 1 :** Utiliser une source de vÃ©ritÃ© unique (le rÃ©fÃ©rentiel de catÃ©gories) pour garantir la fiabilitÃ© des labels.
* **DÃ©cision 2 :** Filtrer les catÃ©gories ayant un support infÃ©rieur Ã  10 Ã©chantillons.
    * **Justification :** Il est statistiquement non pertinent d'entraÃ®ner un modÃ¨le sur des classes avec si peu d'exemples. Cela stabilise l'apprentissage et donne des mÃ©triques plus rÃ©alistes.
* **DÃ©cision 3 :** IntÃ©grer la `brand` aux features textuelles (`product_name_decli`, `summary`, `description`).
    * **Justification :** La marque contient un signal sÃ©mantique fort qui peut aider Ã  dÃ©sambiguÃ¯ser certains produits.

### 2. Choix des ModÃ¨les

* **Approche 1 : Baseline Classique (TF-IDF + RÃ©gression Logistique)**
    * **Choix :** Un pipeline `scikit-learn` avec un prÃ©-traitement de texte avancÃ© (lemmatisation via `spaCy`) et un classifieur linÃ©aire.
    * **Justification :** Permet d'Ã©tablir une performance de rÃ©fÃ©rence solide de maniÃ¨re rapide et peu coÃ»teuse. C'est un excellent candidat pour une mise en production rapide oÃ¹ la vitesse et la simplicitÃ© sont prioritaires.
* **Approche 2 : Deep Learning (Fine-tuning de CamemBERT)**
    * **Choix :** Fine-tuning d'un modÃ¨le Transformer prÃ©-entraÃ®nÃ©, spÃ©cialisÃ© pour le franÃ§ais.
    * **Justification :** Vise la performance de pointe en exploitant la capacitÃ© du modÃ¨le Ã  comprendre le contexte et la sÃ©mantique du texte, ce qui est particuliÃ¨rement utile pour les cas ambigus et les catÃ©gories rares.

### 3. Ã‰valuation et Comparaison

* **MÃ©thodologie :** Un jeu d'Ã©valuation de 200 produits a Ã©tÃ© crÃ©Ã© via un **Ã©chantillonnage stratifiÃ©** pour une comparaison Ã©quitable des deux modÃ¨les.
* **RÃ©sultats :**
    * Le **modÃ¨le classique** a atteint une performance remarquable de **98% de prÃ©cision**, mais a montrÃ© des faiblesses sur les classes les plus rares.
    * Le **modÃ¨le Transformer**, rÃ©-entraÃ®nÃ© avec la `brand`, a atteint **99% de prÃ©cision** et a prouvÃ© sa supÃ©rioritÃ© en classant correctement des catÃ©gories oÃ¹ le modÃ¨le classique Ã©chouait.
* **Conclusion :** Bien que le modÃ¨le Transformer soit techniquement supÃ©rieur, le modÃ¨le classique reprÃ©sente une alternative trÃ¨s compÃ©titive, offrant un excellent compromis entre performance et coÃ»t. Le choix final dÃ©pendrait des contraintes du projet (besoin de prÃ©cision maximale vs. besoin de rapiditÃ© et de simplicitÃ©).

---

## ğŸ”® Pistes d'AmÃ©lioration Futures

* **Analyse d'Erreurs :** Utiliser la matrice de confusion pour analyser en profondeur les erreurs du Transformer et comprendre les confusions rÃ©siduelles.
* **Hyperparameter Tuning :** Utiliser des librairies comme `Optuna` ou `Ray Tune` pour optimiser les hyperparamÃ¨tres des deux modÃ¨les et potentiellement gagner les derniers points de performance.
* **Cross-Validation :** Pour le modÃ¨le classique (qui est rapide), mettre en place une validation croisÃ©e (k-fold) pour obtenir une estimation encore plus robuste de sa performance.
* **DÃ©ploiement Ã  l'Ã©chelle :** Pour une application Ã  fort trafic, dÃ©ployer le modÃ¨le optimisÃ© (`.onnx`) via un serveur d'infÃ©rence dÃ©diÃ© (ex: NVIDIA Triton) pour maximiser le dÃ©bit.
