# üö¥‚Äç‚ôÇÔ∏è Classification de Cat√©gories de Produits V√©lo

## Introduction

Solution et  Test Technique ‚Äì Data Scientist chez Jungle Bike  : classification de produits de v√©lo √† partir de texte. 

* **D√©mo en Ligne :** [Lien vers l'application Gradio sur Hugging Face Spaces](https://huggingface.co/spaces/belkacemsaad/demo_JungleBike)
* **Auteur :** Saad Belkacem

---

## Tableau Comparatif des Performances 

| M√©trique | Mod√®le Classique (TF-IDF + LogReg) | Mod√®le Transformer (CamemBERT) | 
| :--- | :--- | :--- | :--- |
| **Pr√©cision | 98.0% | **99.0%** | 
| **F1-Score  | 98.0% | **99.0%** | 
| **Temps d'Entra√Ænement** | **~ 5 minute** | ~ 3 heures (sur GPU) |  
| **Vitesse d'Inf√©rence (CPU)** | **~ 11 IPS** | Lente | 


---

##  Structure du Projet

Le projet est organis√© de mani√®re modulaire pour une meilleure clart√© et maintenabilit√©.

```
.
‚îú‚îÄ‚îÄ classic_ml/               # Pipeline du mod√®le TF-IDF + LogReg
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ data.py
‚îÇ   ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îî‚îÄ‚îÄ train.py
‚îú‚îÄ‚îÄ data/                       # (non versionn√©es par Git)
‚îú‚îÄ‚îÄ evaluation/                 # Evaluation
‚îÇ   ‚îú‚îÄ‚îÄ classic_model_results/
‚îÇ   ‚îú‚îÄ‚îÄ transformer_model_results/
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_classic.py
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_transformer.py
‚îú‚îÄ‚îÄ models/                     # Mod√®les 
‚îÇ   ‚îú‚îÄ‚îÄ classic_model.joblib
‚îÇ   ‚îú‚îÄ‚îÄ product_classifier.onnx
‚îÇ   ‚îî‚îÄ‚îÄ dataset_target_map.json
‚îú‚îÄ‚îÄ scripts/                    # Scripts d'action pour le pipeline Transformer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ export_and_benchmark.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îî‚îÄ‚îÄ train.py
‚îú‚îÄ‚îÄ src/                        
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/                      # Tests unitaires
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py
‚îú‚îÄ‚îÄ app.py                      # app Gradio
‚îú‚îÄ‚îÄ pyproject.toml              # Fichier de configuration Poetry
‚îî‚îÄ‚îÄ README.md                   # Ce document
```

---

## ‚öôÔ∏è Guide d'Installation et d'Utilisation

Ce guide d√©taille comment installer l'environnement et ex√©cuter chaque script du projet.

###  Installation

Le projet utilise **Poetry** pour la gestion de l'environnement et des d√©pendances.

```bash
# 1. Cloner le d√©p√¥t
git clone https://github.com/blkq1754/Jungle-Bike.git
cd Jungle-Bike

# 2. Installer les d√©pendances
poetry install
```

###  Workflow

#### Tester l'Environnement

Ce script valide que la pr√©paration des donn√©es fonctionne comme pr√©vu.

```bash
poetry run pytest
```

#### √âtape B : Pr√©-traitement dataset pour le Mod√®le Transformer

Ce script pr√©pare et tokenize les donn√©es, n√©cessaire avant d'entra√Æner le mod√®le Transformer.

```bash
poetry run python -m scripts.preprocess
```

####  Entra√Ænement des Mod√®les (Optionnel)

Les mod√®les √©tant d√©j√† fournis, cette √©tape est optionnelle.

* **Entra√Æner le Mod√®le Classique (TF-IDF + LogReg) :**
    ```bash
    poetry run python -m classic_ml.train
    ```
* **Entra√Æner le Mod√®le CamemBERT (fine tuning) :**
    ```bash
    poetry run python -m scripts.train
    ```

#### √âvaluation

Ces scripts g√©n√®rent les rapports de performance et les matrices de confusion dans le dossier `evaluation/`.

* **√âvaluer le Mod√®le Classique :**
    ```bash
    poetry run python -m evaluation.evaluate_classic
    ```
* **√âvaluer le Mod√®le Transformer :**
    ```bash
    poetry run python -m evaluation.evaluate_transformer
    ```

#### Lancer l'app gradio

```bash
poetry run python app.py
```

---

##  D√©marche Technique 

### 1. Pr√©paration du Dataset

* **Probl√®me :** Incoh√©rence des labels et distribution tr√®s d√©s√©quilibr√©e des cat√©gories => Utiliser une source de v√©rit√© unique (le r√©f√©rentiel de cat√©gories) pour garantir la fiabilit√© des labels.
*  Filtrer les cat√©gories ayant un support inf√©rieur √† 50 √©chantillons.: Il est snon pertinent d'entra√Æner un mod√®le sur des classes avec si peu d'exemples. 
*  Les features textuelles :  (`product_name_decli`, `summary`, `description`,`brand` :  'brand' un bien remplit dans le dataset et peut aider √† identifier certaines cat√©gories.

### 2. Choix des Mod√®les

* **Approche 1 : Baseline Classique (TF-IDF + R√©gression Logistique)**
    * **Choix :** Un pipeline `scikit-learn` avec un pr√©-traitement de texte avanc√© (lemmatisation via `spaCy`) et un classifieur lin√©aire.
    * **Justification :** Permet d'√©tablir une performance de r√©f√©rence solide de mani√®re rapide et peu co√ªteuse. C'est un excellent candidat pour une mise en production rapide o√π la vitesse et la simplicit√© sont prioritaires.
* **Approche 2 : Deep Learning (Fine-tuning de CamemBERT)**
    * **Choix :** Fine-tuning d'un mod√®le Transformer pr√©-entra√Æn√©, sp√©cialis√© pour le fran√ßais.
    * **Justification :** Vise la performance de pointe en exploitant la capacit√© du mod√®le √† comprendre le contexte et la s√©mantique du texte, ce qui est particuli√®rement utile pour les cas ambigus et les cat√©gories rares.

### 3. √âvaluation et Comparaison

* **M√©thodologie :** Un jeu d'√©valuation de 200 produits a √©t√© cr√©√© via un **√©chantillonnage stratifi√©** pour une comparaison √©quitable des deux mod√®les.
* **R√©sultats :**
    * Le **mod√®le classique** a atteint une performance remarquable de **98% de pr√©cision**, mais a montr√© des faiblesses sur les classes les plus rares.
    * Le **mod√®le Transformer**, r√©-entra√Æn√© avec la `brand`, a atteint **99% de pr√©cision** et a prouv√© sa sup√©riorit√© en classant correctement des cat√©gories o√π le mod√®le classique √©chouait.
* **Conclusion :** Bien que le mod√®le Transformer soit techniquement sup√©rieur, le mod√®le classique repr√©sente une alternative tr√®s comp√©titive, offrant un excellent compromis entre performance et co√ªt. Le choix final d√©pendrait des contraintes du projet (besoin de pr√©cision maximale vs. besoin de rapidit√© et de simplicit√©).

---

## üîÆ Pistes d'Am√©lioration Futures

* **Analyse d'Erreurs :** Utiliser la matrice de confusion pour analyser en profondeur les erreurs du Transformer et comprendre les confusions r√©siduelles.
* **Hyperparameter Tuning :** Utiliser des librairies comme `Optuna` ou `Ray Tune` pour optimiser les hyperparam√®tres des deux mod√®les et potentiellement gagner les derniers points de performance.
* **Cross-Validation :** Pour le mod√®le classique (qui est rapide), mettre en place une validation crois√©e (k-fold) pour obtenir une estimation encore plus robuste de sa performance.
* **D√©ploiement √† l'√©chelle :** Pour une application √† fort trafic, d√©ployer le mod√®le optimis√© (`.onnx`) via un serveur d'inf√©rence d√©di√© (ex: NVIDIA Triton) pour maximiser le d√©bit.
